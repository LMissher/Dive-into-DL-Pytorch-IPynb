{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络（LeNet）\n",
    "在$3.9$节（多层感知机的从零开始实现）里我们构造了一个含单隐藏层的多层感知机模型来对$Fashion-MNIST$数据集中的图像进行分类。每张图像高和宽均是28像素。我们将图像中的像素逐行展开，得到长度为$784$的向量，并输入进全连接层中。然而，这种分类方法有一定的局限性。\n",
    "\n",
    "1. 图像在**同一列**邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别。\n",
    "2. 对于大尺寸的输入图像，使用全连接层容易造成模型过大。假设输入是高和宽均为$1000$像素的彩色照片（含$3$个通道）。即使全连接层输出个数仍是$256$，该层权重参数的形状是$3,000,000\\times 256$：它占用了大约$3$ $GB$的内存或显存。这带来过**复杂的模型和过高的存储开销**。\n",
    "\n",
    "卷积层尝试解决这两个问题。一方面，**卷积层保留输入形状**，使图像的像素在高和宽两个方向上的相关性均可能被有效识别；另一方面，**卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算**，从而避免参数尺寸过大。\n",
    "\n",
    "卷积神经网络就是含卷积层的网络。本节里我们将介绍一个早期用来识别手写数字图像的卷积神经网络：$LeNet$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet模型\n",
    "$LeNet$分为**卷积层块**和**全连接层块**两个部分。下面我们分别介绍这两个模块。\n",
    "\n",
    "卷积层块里的基本单位是**卷积层后接最大池化层**：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的**最大池化层则用来降低卷积层对位置的敏感性**。卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用$5\\times 5$的窗口，并在输出上使用$sigmoid$激活函数。第一个卷积层输出通道数为$6$，第二个卷积层输出通道数则增加到$16$。这是因为**第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似**。卷积层块的两个最大池化层的窗口形状均为$2\\times 2$，且步幅为$2$。由于池化窗口与步幅形状相同，**池化窗口在输入上每次滑动所覆盖的区域互不重叠**。\n",
    "\n",
    "卷积层块的输出形状为 **(批量大小, 通道, 高, 宽)**。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平$（flatten）$。也就是说，全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且**向量长度为通道、高和宽的乘积**。全连接层块含$3$个全连接层。它们的输出个数分别是$120$、$84$和$10$，其中$10$为输出的类别个数。\n",
    "\n",
    "下面我们通过$Sequential$类来实现$LeNet$模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:7\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "from d2lzh_pytorch import evaluate_accuracy\n",
    "device = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来查看每个层的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，在卷积层块中输入的高和宽在逐层减小。卷积层由于使用**高和宽均为$5$的卷积核，从而将高和宽分别减小$4$，而池化层则将高和宽减半**，但通道数则从1增加到16。全连接层则逐层减少输出个数，直到变成图像的类别数10。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据和训练模型\n",
    "下面我们来实验$LeNet$模型。实验中，我们仍然使用$Fashion-MNIST$作为训练数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size, root='~/wms/Jupyter/fyc/Datasets/FashionMNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on:\",device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1,epochs+1):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net, device=device)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习率采用$0.001$，训练算法使用$Adam$算法，损失函数使用交叉熵损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on: cuda:7\n",
      "step 1, train_acc: 0.1016\n",
      "step 2, train_acc: 0.1133\n",
      "step 3, train_acc: 0.1133\n",
      "step 4, train_acc: 0.1035\n",
      "step 5, train_acc: 0.1031\n",
      "step 6, train_acc: 0.0964\n",
      "step 7, train_acc: 0.0960\n",
      "step 8, train_acc: 0.1035\n",
      "step 9, train_acc: 0.1011\n",
      "step 10, train_acc: 0.1020\n",
      "step 11, train_acc: 0.1023\n",
      "step 12, train_acc: 0.1016\n",
      "step 13, train_acc: 0.1037\n",
      "step 14, train_acc: 0.1038\n",
      "step 15, train_acc: 0.1021\n",
      "step 16, train_acc: 0.1028\n",
      "step 17, train_acc: 0.1059\n",
      "step 18, train_acc: 0.1057\n",
      "step 19, train_acc: 0.1057\n",
      "step 20, train_acc: 0.1049\n",
      "step 21, train_acc: 0.1045\n",
      "step 22, train_acc: 0.1053\n",
      "step 23, train_acc: 0.1050\n",
      "step 24, train_acc: 0.1056\n",
      "step 25, train_acc: 0.1052\n",
      "step 26, train_acc: 0.1050\n",
      "step 27, train_acc: 0.1039\n",
      "step 28, train_acc: 0.1042\n",
      "step 29, train_acc: 0.1045\n",
      "step 30, train_acc: 0.1048\n",
      "step 31, train_acc: 0.1043\n",
      "step 32, train_acc: 0.1041\n",
      "step 33, train_acc: 0.1040\n",
      "step 34, train_acc: 0.1035\n",
      "step 35, train_acc: 0.1066\n",
      "step 36, train_acc: 0.1075\n",
      "step 37, train_acc: 0.1082\n",
      "step 38, train_acc: 0.1072\n",
      "step 39, train_acc: 0.1074\n",
      "step 40, train_acc: 0.1076\n",
      "step 41, train_acc: 0.1070\n",
      "step 42, train_acc: 0.1068\n",
      "step 43, train_acc: 0.1073\n",
      "step 44, train_acc: 0.1070\n",
      "step 45, train_acc: 0.1069\n",
      "step 46, train_acc: 0.1066\n",
      "step 47, train_acc: 0.1069\n",
      "step 48, train_acc: 0.1072\n",
      "step 49, train_acc: 0.1074\n",
      "step 50, train_acc: 0.1074\n",
      "step 51, train_acc: 0.1072\n",
      "step 52, train_acc: 0.1077\n",
      "step 53, train_acc: 0.1072\n",
      "step 54, train_acc: 0.1066\n",
      "step 55, train_acc: 0.1067\n",
      "step 56, train_acc: 0.1066\n",
      "step 57, train_acc: 0.1062\n",
      "step 58, train_acc: 0.1062\n",
      "step 59, train_acc: 0.1062\n",
      "step 60, train_acc: 0.1077\n",
      "step 61, train_acc: 0.1106\n",
      "step 62, train_acc: 0.1103\n",
      "step 63, train_acc: 0.1102\n",
      "step 64, train_acc: 0.1110\n",
      "step 65, train_acc: 0.1111\n",
      "step 66, train_acc: 0.1104\n",
      "step 67, train_acc: 0.1102\n",
      "step 68, train_acc: 0.1108\n",
      "step 69, train_acc: 0.1119\n",
      "step 70, train_acc: 0.1122\n",
      "step 71, train_acc: 0.1128\n",
      "step 72, train_acc: 0.1133\n",
      "step 73, train_acc: 0.1137\n",
      "step 74, train_acc: 0.1135\n",
      "step 75, train_acc: 0.1137\n",
      "step 76, train_acc: 0.1132\n",
      "step 77, train_acc: 0.1129\n",
      "step 78, train_acc: 0.1134\n",
      "step 79, train_acc: 0.1147\n",
      "step 80, train_acc: 0.1160\n",
      "step 81, train_acc: 0.1168\n",
      "step 82, train_acc: 0.1170\n",
      "step 83, train_acc: 0.1170\n",
      "step 84, train_acc: 0.1173\n",
      "step 85, train_acc: 0.1178\n",
      "step 86, train_acc: 0.1190\n",
      "step 87, train_acc: 0.1197\n",
      "step 88, train_acc: 0.1203\n",
      "step 89, train_acc: 0.1212\n",
      "step 90, train_acc: 0.1219\n",
      "step 91, train_acc: 0.1233\n",
      "step 92, train_acc: 0.1245\n",
      "step 93, train_acc: 0.1259\n",
      "step 94, train_acc: 0.1275\n",
      "step 95, train_acc: 0.1292\n",
      "step 96, train_acc: 0.1303\n",
      "step 97, train_acc: 0.1314\n",
      "step 98, train_acc: 0.1328\n",
      "step 99, train_acc: 0.1338\n",
      "step 100, train_acc: 0.1353\n",
      "step 101, train_acc: 0.1370\n",
      "step 102, train_acc: 0.1384\n",
      "step 103, train_acc: 0.1404\n",
      "step 104, train_acc: 0.1424\n",
      "step 105, train_acc: 0.1447\n",
      "step 106, train_acc: 0.1461\n",
      "step 107, train_acc: 0.1477\n",
      "step 108, train_acc: 0.1489\n",
      "step 109, train_acc: 0.1509\n",
      "step 110, train_acc: 0.1527\n",
      "step 111, train_acc: 0.1545\n",
      "step 112, train_acc: 0.1566\n",
      "step 113, train_acc: 0.1579\n",
      "step 114, train_acc: 0.1600\n",
      "step 115, train_acc: 0.1617\n",
      "step 116, train_acc: 0.1634\n",
      "step 117, train_acc: 0.1651\n",
      "step 118, train_acc: 0.1671\n",
      "step 119, train_acc: 0.1687\n",
      "step 120, train_acc: 0.1704\n",
      "step 121, train_acc: 0.1724\n",
      "step 122, train_acc: 0.1743\n",
      "step 123, train_acc: 0.1762\n",
      "step 124, train_acc: 0.1782\n",
      "step 125, train_acc: 0.1800\n",
      "step 126, train_acc: 0.1820\n",
      "step 127, train_acc: 0.1838\n",
      "step 128, train_acc: 0.1857\n",
      "step 129, train_acc: 0.1872\n",
      "step 130, train_acc: 0.1890\n",
      "step 131, train_acc: 0.1909\n",
      "step 132, train_acc: 0.1927\n",
      "step 133, train_acc: 0.1944\n",
      "step 134, train_acc: 0.1963\n",
      "step 135, train_acc: 0.1980\n",
      "step 136, train_acc: 0.1996\n",
      "step 137, train_acc: 0.2016\n",
      "step 138, train_acc: 0.2032\n",
      "step 139, train_acc: 0.2046\n",
      "step 140, train_acc: 0.2059\n",
      "step 141, train_acc: 0.2075\n",
      "step 142, train_acc: 0.2094\n",
      "step 143, train_acc: 0.2110\n",
      "step 144, train_acc: 0.2122\n",
      "step 145, train_acc: 0.2133\n",
      "step 146, train_acc: 0.2147\n",
      "step 147, train_acc: 0.2166\n",
      "step 148, train_acc: 0.2180\n",
      "step 149, train_acc: 0.2200\n",
      "step 150, train_acc: 0.2219\n",
      "step 151, train_acc: 0.2238\n",
      "step 152, train_acc: 0.2256\n",
      "step 153, train_acc: 0.2274\n",
      "step 154, train_acc: 0.2295\n",
      "step 155, train_acc: 0.2312\n",
      "step 156, train_acc: 0.2327\n",
      "step 157, train_acc: 0.2345\n",
      "step 158, train_acc: 0.2364\n",
      "step 159, train_acc: 0.2381\n",
      "step 160, train_acc: 0.2396\n",
      "step 161, train_acc: 0.2411\n",
      "step 162, train_acc: 0.2429\n",
      "step 163, train_acc: 0.2444\n",
      "step 164, train_acc: 0.2457\n",
      "step 165, train_acc: 0.2475\n",
      "step 166, train_acc: 0.2493\n",
      "step 167, train_acc: 0.2509\n",
      "step 168, train_acc: 0.2524\n",
      "step 169, train_acc: 0.2539\n",
      "step 170, train_acc: 0.2554\n",
      "step 171, train_acc: 0.2569\n",
      "step 172, train_acc: 0.2584\n",
      "step 173, train_acc: 0.2595\n",
      "step 174, train_acc: 0.2608\n",
      "step 175, train_acc: 0.2623\n",
      "step 176, train_acc: 0.2636\n",
      "step 177, train_acc: 0.2651\n",
      "step 178, train_acc: 0.2663\n",
      "step 179, train_acc: 0.2677\n",
      "step 180, train_acc: 0.2691\n",
      "step 181, train_acc: 0.2708\n",
      "step 182, train_acc: 0.2725\n",
      "step 183, train_acc: 0.2739\n",
      "step 184, train_acc: 0.2756\n",
      "step 185, train_acc: 0.2770\n",
      "step 186, train_acc: 0.2787\n",
      "step 187, train_acc: 0.2801\n",
      "step 188, train_acc: 0.2816\n",
      "step 189, train_acc: 0.2828\n",
      "step 190, train_acc: 0.2842\n",
      "step 191, train_acc: 0.2856\n",
      "step 192, train_acc: 0.2870\n",
      "step 193, train_acc: 0.2884\n",
      "step 194, train_acc: 0.2896\n",
      "step 195, train_acc: 0.2906\n",
      "step 196, train_acc: 0.2922\n",
      "step 197, train_acc: 0.2937\n",
      "step 198, train_acc: 0.2949\n",
      "step 199, train_acc: 0.2962\n",
      "step 200, train_acc: 0.2978\n",
      "step 201, train_acc: 0.2993\n",
      "step 202, train_acc: 0.3006\n",
      "step 203, train_acc: 0.3017\n",
      "step 204, train_acc: 0.3029\n",
      "step 205, train_acc: 0.3042\n",
      "step 206, train_acc: 0.3054\n",
      "step 207, train_acc: 0.3067\n",
      "step 208, train_acc: 0.3077\n",
      "step 209, train_acc: 0.3090\n",
      "step 210, train_acc: 0.3102\n",
      "step 211, train_acc: 0.3113\n",
      "step 212, train_acc: 0.3124\n",
      "step 213, train_acc: 0.3135\n",
      "step 214, train_acc: 0.3147\n",
      "step 215, train_acc: 0.3159\n",
      "step 216, train_acc: 0.3171\n",
      "step 217, train_acc: 0.3182\n",
      "step 218, train_acc: 0.3194\n",
      "step 219, train_acc: 0.3207\n",
      "step 220, train_acc: 0.3218\n",
      "step 221, train_acc: 0.3229\n",
      "step 222, train_acc: 0.3240\n",
      "step 223, train_acc: 0.3250\n",
      "step 224, train_acc: 0.3263\n",
      "step 225, train_acc: 0.3274\n",
      "step 226, train_acc: 0.3286\n",
      "step 227, train_acc: 0.3298\n",
      "step 228, train_acc: 0.3306\n",
      "step 229, train_acc: 0.3316\n",
      "step 230, train_acc: 0.3328\n",
      "step 231, train_acc: 0.3338\n",
      "step 232, train_acc: 0.3350\n",
      "step 233, train_acc: 0.3361\n",
      "step 234, train_acc: 0.3370\n",
      "step 235, train_acc: 0.3375\n",
      "epoch 1, loss 1.8106, train acc 0.337, test acc 0.585, time 2.8 sec\n",
      "step 1, train_acc: 0.5625\n",
      "step 2, train_acc: 0.5781\n",
      "step 3, train_acc: 0.5807\n",
      "step 4, train_acc: 0.5869\n",
      "step 5, train_acc: 0.5984\n",
      "step 6, train_acc: 0.5911\n",
      "step 7, train_acc: 0.5865\n",
      "step 8, train_acc: 0.5835\n",
      "step 9, train_acc: 0.5864\n",
      "step 10, train_acc: 0.5848\n",
      "step 11, train_acc: 0.5842\n",
      "step 12, train_acc: 0.5879\n",
      "step 13, train_acc: 0.5832\n",
      "step 14, train_acc: 0.5823\n",
      "step 15, train_acc: 0.5810\n",
      "step 16, train_acc: 0.5815\n",
      "step 17, train_acc: 0.5827\n",
      "step 18, train_acc: 0.5822\n",
      "step 19, train_acc: 0.5835\n",
      "step 20, train_acc: 0.5832\n",
      "step 21, train_acc: 0.5865\n",
      "step 22, train_acc: 0.5870\n",
      "step 23, train_acc: 0.5878\n",
      "step 24, train_acc: 0.5858\n",
      "step 25, train_acc: 0.5872\n",
      "step 26, train_acc: 0.5868\n",
      "step 27, train_acc: 0.5880\n",
      "step 28, train_acc: 0.5875\n",
      "step 29, train_acc: 0.5881\n",
      "step 30, train_acc: 0.5887\n",
      "step 31, train_acc: 0.5890\n",
      "step 32, train_acc: 0.5879\n",
      "step 33, train_acc: 0.5889\n",
      "step 34, train_acc: 0.5888\n",
      "step 35, train_acc: 0.5910\n",
      "step 36, train_acc: 0.5910\n",
      "step 37, train_acc: 0.5920\n",
      "step 38, train_acc: 0.5923\n",
      "step 39, train_acc: 0.5918\n",
      "step 40, train_acc: 0.5913\n",
      "step 41, train_acc: 0.5914\n",
      "step 42, train_acc: 0.5902\n",
      "step 43, train_acc: 0.5900\n",
      "step 44, train_acc: 0.5906\n",
      "step 45, train_acc: 0.5917\n",
      "step 46, train_acc: 0.5913\n",
      "step 47, train_acc: 0.5908\n",
      "step 48, train_acc: 0.5916\n",
      "step 49, train_acc: 0.5926\n",
      "step 50, train_acc: 0.5941\n",
      "step 51, train_acc: 0.5944\n",
      "step 52, train_acc: 0.5945\n",
      "step 53, train_acc: 0.5943\n",
      "step 54, train_acc: 0.5948\n",
      "step 55, train_acc: 0.5945\n",
      "step 56, train_acc: 0.5949\n",
      "step 57, train_acc: 0.5945\n",
      "step 58, train_acc: 0.5949\n",
      "step 59, train_acc: 0.5955\n",
      "step 60, train_acc: 0.5957\n",
      "step 61, train_acc: 0.5960\n",
      "step 62, train_acc: 0.5970\n",
      "step 63, train_acc: 0.5972\n",
      "step 64, train_acc: 0.5967\n",
      "step 65, train_acc: 0.5966\n",
      "step 66, train_acc: 0.5964\n",
      "step 67, train_acc: 0.5963\n",
      "step 68, train_acc: 0.5972\n",
      "step 69, train_acc: 0.5969\n",
      "step 70, train_acc: 0.5975\n",
      "step 71, train_acc: 0.5979\n",
      "step 72, train_acc: 0.5980\n",
      "step 73, train_acc: 0.5980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 74, train_acc: 0.5979\n",
      "step 75, train_acc: 0.5976\n",
      "step 76, train_acc: 0.5976\n",
      "step 77, train_acc: 0.5974\n",
      "step 78, train_acc: 0.5970\n",
      "step 79, train_acc: 0.5965\n",
      "step 80, train_acc: 0.5965\n",
      "step 81, train_acc: 0.5966\n",
      "step 82, train_acc: 0.5965\n",
      "step 83, train_acc: 0.5960\n",
      "step 84, train_acc: 0.5960\n",
      "step 85, train_acc: 0.5966\n",
      "step 86, train_acc: 0.5961\n",
      "step 87, train_acc: 0.5959\n",
      "step 88, train_acc: 0.5956\n",
      "step 89, train_acc: 0.5963\n",
      "step 90, train_acc: 0.5966\n",
      "step 91, train_acc: 0.5968\n",
      "step 92, train_acc: 0.5970\n",
      "step 93, train_acc: 0.5978\n",
      "step 94, train_acc: 0.5980\n",
      "step 95, train_acc: 0.5982\n",
      "step 96, train_acc: 0.5981\n",
      "step 97, train_acc: 0.5987\n",
      "step 98, train_acc: 0.5989\n",
      "step 99, train_acc: 0.5995\n",
      "step 100, train_acc: 0.5997\n",
      "step 101, train_acc: 0.5996\n",
      "step 102, train_acc: 0.5998\n",
      "step 103, train_acc: 0.5997\n",
      "step 104, train_acc: 0.5998\n",
      "step 105, train_acc: 0.5996\n",
      "step 106, train_acc: 0.5995\n",
      "step 107, train_acc: 0.6001\n",
      "step 108, train_acc: 0.6000\n",
      "step 109, train_acc: 0.6001\n",
      "step 110, train_acc: 0.6003\n",
      "step 111, train_acc: 0.6006\n",
      "step 112, train_acc: 0.6006\n",
      "step 113, train_acc: 0.6006\n",
      "step 114, train_acc: 0.6008\n",
      "step 115, train_acc: 0.6014\n",
      "step 116, train_acc: 0.6013\n",
      "step 117, train_acc: 0.6017\n",
      "step 118, train_acc: 0.6016\n",
      "step 119, train_acc: 0.6014\n",
      "step 120, train_acc: 0.6018\n",
      "step 121, train_acc: 0.6020\n",
      "step 122, train_acc: 0.6021\n",
      "step 123, train_acc: 0.6024\n",
      "step 124, train_acc: 0.6028\n",
      "step 125, train_acc: 0.6029\n",
      "step 126, train_acc: 0.6028\n",
      "step 127, train_acc: 0.6035\n",
      "step 128, train_acc: 0.6035\n",
      "step 129, train_acc: 0.6041\n",
      "step 130, train_acc: 0.6044\n",
      "step 131, train_acc: 0.6045\n",
      "step 132, train_acc: 0.6046\n",
      "step 133, train_acc: 0.6047\n",
      "step 134, train_acc: 0.6045\n",
      "step 135, train_acc: 0.6044\n",
      "step 136, train_acc: 0.6044\n",
      "step 137, train_acc: 0.6047\n",
      "step 138, train_acc: 0.6046\n",
      "step 139, train_acc: 0.6048\n",
      "step 140, train_acc: 0.6045\n",
      "step 141, train_acc: 0.6049\n",
      "step 142, train_acc: 0.6049\n",
      "step 143, train_acc: 0.6054\n",
      "step 144, train_acc: 0.6059\n",
      "step 145, train_acc: 0.6061\n",
      "step 146, train_acc: 0.6060\n",
      "step 147, train_acc: 0.6059\n",
      "step 148, train_acc: 0.6058\n",
      "step 149, train_acc: 0.6062\n",
      "step 150, train_acc: 0.6063\n",
      "step 151, train_acc: 0.6062\n",
      "step 152, train_acc: 0.6064\n",
      "step 153, train_acc: 0.6067\n",
      "step 154, train_acc: 0.6069\n",
      "step 155, train_acc: 0.6075\n",
      "step 156, train_acc: 0.6075\n",
      "step 157, train_acc: 0.6078\n",
      "step 158, train_acc: 0.6081\n",
      "step 159, train_acc: 0.6082\n",
      "step 160, train_acc: 0.6084\n",
      "step 161, train_acc: 0.6086\n",
      "step 162, train_acc: 0.6086\n",
      "step 163, train_acc: 0.6089\n",
      "step 164, train_acc: 0.6089\n",
      "step 165, train_acc: 0.6089\n",
      "step 166, train_acc: 0.6090\n",
      "step 167, train_acc: 0.6086\n",
      "step 168, train_acc: 0.6091\n",
      "step 169, train_acc: 0.6091\n",
      "step 170, train_acc: 0.6097\n",
      "step 171, train_acc: 0.6103\n",
      "step 172, train_acc: 0.6106\n",
      "step 173, train_acc: 0.6110\n",
      "step 174, train_acc: 0.6110\n",
      "step 175, train_acc: 0.6113\n",
      "step 176, train_acc: 0.6116\n",
      "step 177, train_acc: 0.6113\n",
      "step 178, train_acc: 0.6114\n",
      "step 179, train_acc: 0.6115\n",
      "step 180, train_acc: 0.6118\n",
      "step 181, train_acc: 0.6121\n",
      "step 182, train_acc: 0.6124\n",
      "step 183, train_acc: 0.6126\n",
      "step 184, train_acc: 0.6128\n",
      "step 185, train_acc: 0.6130\n",
      "step 186, train_acc: 0.6133\n",
      "step 187, train_acc: 0.6132\n",
      "step 188, train_acc: 0.6135\n",
      "step 189, train_acc: 0.6140\n",
      "step 190, train_acc: 0.6140\n",
      "step 191, train_acc: 0.6140\n",
      "step 192, train_acc: 0.6141\n",
      "step 193, train_acc: 0.6147\n",
      "step 194, train_acc: 0.6150\n",
      "step 195, train_acc: 0.6151\n",
      "step 196, train_acc: 0.6157\n",
      "step 197, train_acc: 0.6158\n",
      "step 198, train_acc: 0.6164\n",
      "step 199, train_acc: 0.6164\n",
      "step 200, train_acc: 0.6164\n",
      "step 201, train_acc: 0.6165\n",
      "step 202, train_acc: 0.6166\n",
      "step 203, train_acc: 0.6169\n",
      "step 204, train_acc: 0.6173\n",
      "step 205, train_acc: 0.6175\n",
      "step 206, train_acc: 0.6176\n",
      "step 207, train_acc: 0.6179\n",
      "step 208, train_acc: 0.6182\n",
      "step 209, train_acc: 0.6183\n",
      "step 210, train_acc: 0.6186\n",
      "step 211, train_acc: 0.6190\n",
      "step 212, train_acc: 0.6192\n",
      "step 213, train_acc: 0.6195\n",
      "step 214, train_acc: 0.6197\n",
      "step 215, train_acc: 0.6199\n",
      "step 216, train_acc: 0.6200\n",
      "step 217, train_acc: 0.6203\n",
      "step 218, train_acc: 0.6204\n",
      "step 219, train_acc: 0.6205\n",
      "step 220, train_acc: 0.6206\n",
      "step 221, train_acc: 0.6209\n",
      "step 222, train_acc: 0.6211\n",
      "step 223, train_acc: 0.6214\n",
      "step 224, train_acc: 0.6216\n",
      "step 225, train_acc: 0.6217\n",
      "step 226, train_acc: 0.6219\n",
      "step 227, train_acc: 0.6221\n",
      "step 228, train_acc: 0.6224\n",
      "step 229, train_acc: 0.6226\n",
      "step 230, train_acc: 0.6228\n",
      "step 231, train_acc: 0.6229\n",
      "step 232, train_acc: 0.6232\n",
      "step 233, train_acc: 0.6235\n",
      "step 234, train_acc: 0.6239\n",
      "step 235, train_acc: 0.6239\n",
      "epoch 2, loss 0.9511, train acc 0.624, test acc 0.678, time 2.2 sec\n",
      "step 1, train_acc: 0.6680\n",
      "step 2, train_acc: 0.6719\n",
      "step 3, train_acc: 0.6719\n",
      "step 4, train_acc: 0.6895\n",
      "step 5, train_acc: 0.7000\n",
      "step 6, train_acc: 0.6934\n",
      "step 7, train_acc: 0.6825\n",
      "step 8, train_acc: 0.6875\n",
      "step 9, train_acc: 0.6892\n",
      "step 10, train_acc: 0.6926\n",
      "step 11, train_acc: 0.6896\n",
      "step 12, train_acc: 0.6872\n",
      "step 13, train_acc: 0.6860\n",
      "step 14, train_acc: 0.6878\n",
      "step 15, train_acc: 0.6891\n",
      "step 16, train_acc: 0.6897\n",
      "step 17, train_acc: 0.6919\n",
      "step 18, train_acc: 0.6914\n",
      "step 19, train_acc: 0.6916\n",
      "step 20, train_acc: 0.6902\n",
      "step 21, train_acc: 0.6903\n",
      "step 22, train_acc: 0.6891\n",
      "step 23, train_acc: 0.6867\n",
      "step 24, train_acc: 0.6852\n",
      "step 25, train_acc: 0.6864\n",
      "step 26, train_acc: 0.6857\n",
      "step 27, train_acc: 0.6862\n",
      "step 28, train_acc: 0.6854\n",
      "step 29, train_acc: 0.6845\n",
      "step 30, train_acc: 0.6850\n",
      "step 31, train_acc: 0.6849\n",
      "step 32, train_acc: 0.6852\n",
      "step 33, train_acc: 0.6851\n",
      "step 34, train_acc: 0.6861\n",
      "step 35, train_acc: 0.6872\n",
      "step 36, train_acc: 0.6880\n",
      "step 37, train_acc: 0.6877\n",
      "step 38, train_acc: 0.6876\n",
      "step 39, train_acc: 0.6865\n",
      "step 40, train_acc: 0.6864\n",
      "step 41, train_acc: 0.6859\n",
      "step 42, train_acc: 0.6862\n",
      "step 43, train_acc: 0.6850\n",
      "step 44, train_acc: 0.6834\n",
      "step 45, train_acc: 0.6845\n",
      "step 46, train_acc: 0.6842\n",
      "step 47, train_acc: 0.6834\n",
      "step 48, train_acc: 0.6829\n",
      "step 49, train_acc: 0.6830\n",
      "step 50, train_acc: 0.6834\n",
      "step 51, train_acc: 0.6834\n",
      "step 52, train_acc: 0.6840\n",
      "step 53, train_acc: 0.6834\n",
      "step 54, train_acc: 0.6848\n",
      "step 55, train_acc: 0.6847\n",
      "step 56, train_acc: 0.6858\n",
      "step 57, train_acc: 0.6860\n",
      "step 58, train_acc: 0.6864\n",
      "step 59, train_acc: 0.6860\n",
      "step 60, train_acc: 0.6861\n",
      "step 61, train_acc: 0.6864\n",
      "step 62, train_acc: 0.6866\n",
      "step 63, train_acc: 0.6875\n",
      "step 64, train_acc: 0.6880\n",
      "step 65, train_acc: 0.6883\n",
      "step 66, train_acc: 0.6889\n",
      "step 67, train_acc: 0.6899\n",
      "step 68, train_acc: 0.6907\n",
      "step 69, train_acc: 0.6910\n",
      "step 70, train_acc: 0.6917\n",
      "step 71, train_acc: 0.6919\n",
      "step 72, train_acc: 0.6929\n",
      "step 73, train_acc: 0.6931\n",
      "step 74, train_acc: 0.6934\n",
      "step 75, train_acc: 0.6932\n",
      "step 76, train_acc: 0.6937\n",
      "step 77, train_acc: 0.6940\n",
      "step 78, train_acc: 0.6938\n",
      "step 79, train_acc: 0.6936\n",
      "step 80, train_acc: 0.6932\n",
      "step 81, train_acc: 0.6931\n",
      "step 82, train_acc: 0.6935\n",
      "step 83, train_acc: 0.6932\n",
      "step 84, train_acc: 0.6926\n",
      "step 85, train_acc: 0.6930\n",
      "step 86, train_acc: 0.6935\n",
      "step 87, train_acc: 0.6928\n",
      "step 88, train_acc: 0.6928\n",
      "step 89, train_acc: 0.6928\n",
      "step 90, train_acc: 0.6931\n",
      "step 91, train_acc: 0.6936\n",
      "step 92, train_acc: 0.6937\n",
      "step 93, train_acc: 0.6943\n",
      "step 94, train_acc: 0.6944\n",
      "step 95, train_acc: 0.6948\n",
      "step 96, train_acc: 0.6951\n",
      "step 97, train_acc: 0.6951\n",
      "step 98, train_acc: 0.6951\n",
      "step 99, train_acc: 0.6953\n",
      "step 100, train_acc: 0.6954\n",
      "step 101, train_acc: 0.6960\n",
      "step 102, train_acc: 0.6965\n",
      "step 103, train_acc: 0.6966\n",
      "step 104, train_acc: 0.6970\n",
      "step 105, train_acc: 0.6975\n",
      "step 106, train_acc: 0.6979\n",
      "step 107, train_acc: 0.6985\n",
      "step 108, train_acc: 0.6982\n",
      "step 109, train_acc: 0.6988\n",
      "step 110, train_acc: 0.6990\n",
      "step 111, train_acc: 0.6996\n",
      "step 112, train_acc: 0.7001\n",
      "step 113, train_acc: 0.7007\n",
      "step 114, train_acc: 0.7007\n",
      "step 115, train_acc: 0.7006\n",
      "step 116, train_acc: 0.7007\n",
      "step 117, train_acc: 0.7009\n",
      "step 118, train_acc: 0.7012\n",
      "step 119, train_acc: 0.7013\n",
      "step 120, train_acc: 0.7012\n",
      "step 121, train_acc: 0.7013\n",
      "step 122, train_acc: 0.7016\n",
      "step 123, train_acc: 0.7022\n",
      "step 124, train_acc: 0.7019\n",
      "step 125, train_acc: 0.7019\n",
      "step 126, train_acc: 0.7023\n",
      "step 127, train_acc: 0.7024\n",
      "step 128, train_acc: 0.7024\n",
      "step 129, train_acc: 0.7028\n",
      "step 130, train_acc: 0.7035\n",
      "step 131, train_acc: 0.7032\n",
      "step 132, train_acc: 0.7034\n",
      "step 133, train_acc: 0.7037\n",
      "step 134, train_acc: 0.7039\n",
      "step 135, train_acc: 0.7040\n",
      "step 136, train_acc: 0.7039\n",
      "step 137, train_acc: 0.7036\n",
      "step 138, train_acc: 0.7038\n",
      "step 139, train_acc: 0.7041\n",
      "step 140, train_acc: 0.7045\n",
      "step 141, train_acc: 0.7045\n",
      "step 142, train_acc: 0.7049\n",
      "step 143, train_acc: 0.7049\n",
      "step 144, train_acc: 0.7049\n",
      "step 145, train_acc: 0.7051\n",
      "step 146, train_acc: 0.7051\n",
      "step 147, train_acc: 0.7054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 148, train_acc: 0.7055\n",
      "step 149, train_acc: 0.7053\n",
      "step 150, train_acc: 0.7057\n",
      "step 151, train_acc: 0.7057\n",
      "step 152, train_acc: 0.7060\n",
      "step 153, train_acc: 0.7060\n",
      "step 154, train_acc: 0.7058\n",
      "step 155, train_acc: 0.7058\n",
      "step 156, train_acc: 0.7059\n",
      "step 157, train_acc: 0.7061\n",
      "step 158, train_acc: 0.7062\n",
      "step 159, train_acc: 0.7065\n",
      "step 160, train_acc: 0.7066\n",
      "step 161, train_acc: 0.7064\n",
      "step 162, train_acc: 0.7063\n",
      "step 163, train_acc: 0.7064\n",
      "step 164, train_acc: 0.7063\n",
      "step 165, train_acc: 0.7062\n",
      "step 166, train_acc: 0.7063\n",
      "step 167, train_acc: 0.7064\n",
      "step 168, train_acc: 0.7064\n",
      "step 169, train_acc: 0.7065\n",
      "step 170, train_acc: 0.7068\n",
      "step 171, train_acc: 0.7067\n",
      "step 172, train_acc: 0.7070\n",
      "step 173, train_acc: 0.7073\n",
      "step 174, train_acc: 0.7072\n",
      "step 175, train_acc: 0.7073\n",
      "step 176, train_acc: 0.7076\n",
      "step 177, train_acc: 0.7075\n",
      "step 178, train_acc: 0.7075\n",
      "step 179, train_acc: 0.7079\n",
      "step 180, train_acc: 0.7081\n",
      "step 181, train_acc: 0.7080\n",
      "step 182, train_acc: 0.7080\n",
      "step 183, train_acc: 0.7082\n",
      "step 184, train_acc: 0.7084\n",
      "step 185, train_acc: 0.7086\n",
      "step 186, train_acc: 0.7088\n",
      "step 187, train_acc: 0.7088\n",
      "step 188, train_acc: 0.7088\n",
      "step 189, train_acc: 0.7090\n",
      "step 190, train_acc: 0.7091\n",
      "step 191, train_acc: 0.7093\n",
      "step 192, train_acc: 0.7094\n",
      "step 193, train_acc: 0.7095\n",
      "step 194, train_acc: 0.7098\n",
      "step 195, train_acc: 0.7100\n",
      "step 196, train_acc: 0.7100\n",
      "step 197, train_acc: 0.7103\n",
      "step 198, train_acc: 0.7103\n",
      "step 199, train_acc: 0.7105\n",
      "step 200, train_acc: 0.7106\n",
      "step 201, train_acc: 0.7106\n",
      "step 202, train_acc: 0.7107\n",
      "step 203, train_acc: 0.7108\n",
      "step 204, train_acc: 0.7108\n",
      "step 205, train_acc: 0.7111\n",
      "step 206, train_acc: 0.7112\n",
      "step 207, train_acc: 0.7112\n",
      "step 208, train_acc: 0.7112\n",
      "step 209, train_acc: 0.7111\n",
      "step 210, train_acc: 0.7113\n",
      "step 211, train_acc: 0.7113\n",
      "step 212, train_acc: 0.7114\n",
      "step 213, train_acc: 0.7114\n",
      "step 214, train_acc: 0.7115\n",
      "step 215, train_acc: 0.7118\n",
      "step 216, train_acc: 0.7119\n",
      "step 217, train_acc: 0.7121\n",
      "step 218, train_acc: 0.7124\n",
      "step 219, train_acc: 0.7122\n",
      "step 220, train_acc: 0.7123\n",
      "step 221, train_acc: 0.7125\n",
      "step 222, train_acc: 0.7126\n",
      "step 223, train_acc: 0.7126\n",
      "step 224, train_acc: 0.7122\n",
      "step 225, train_acc: 0.7124\n",
      "step 226, train_acc: 0.7123\n",
      "step 227, train_acc: 0.7123\n",
      "step 228, train_acc: 0.7122\n",
      "step 229, train_acc: 0.7124\n",
      "step 230, train_acc: 0.7123\n",
      "step 231, train_acc: 0.7123\n",
      "step 232, train_acc: 0.7123\n",
      "step 233, train_acc: 0.7125\n",
      "step 234, train_acc: 0.7127\n",
      "step 235, train_acc: 0.7127\n",
      "epoch 3, loss 0.7680, train acc 0.713, test acc 0.730, time 2.5 sec\n",
      "step 1, train_acc: 0.6758\n",
      "step 2, train_acc: 0.7168\n",
      "step 3, train_acc: 0.7031\n",
      "step 4, train_acc: 0.7197\n",
      "step 5, train_acc: 0.7156\n",
      "step 6, train_acc: 0.7298\n",
      "step 7, train_acc: 0.7372\n",
      "step 8, train_acc: 0.7344\n",
      "step 9, train_acc: 0.7348\n",
      "step 10, train_acc: 0.7379\n",
      "step 11, train_acc: 0.7354\n",
      "step 12, train_acc: 0.7324\n",
      "step 13, train_acc: 0.7350\n",
      "step 14, train_acc: 0.7377\n",
      "step 15, train_acc: 0.7393\n",
      "step 16, train_acc: 0.7366\n",
      "step 17, train_acc: 0.7403\n",
      "step 18, train_acc: 0.7415\n",
      "step 19, train_acc: 0.7424\n",
      "step 20, train_acc: 0.7426\n",
      "step 21, train_acc: 0.7418\n",
      "step 22, train_acc: 0.7399\n",
      "step 23, train_acc: 0.7413\n",
      "step 24, train_acc: 0.7430\n",
      "step 25, train_acc: 0.7423\n",
      "step 26, train_acc: 0.7408\n",
      "step 27, train_acc: 0.7410\n",
      "step 28, train_acc: 0.7400\n",
      "step 29, train_acc: 0.7406\n",
      "step 30, train_acc: 0.7385\n",
      "step 31, train_acc: 0.7385\n",
      "step 32, train_acc: 0.7385\n",
      "step 33, train_acc: 0.7379\n",
      "step 34, train_acc: 0.7377\n",
      "step 35, train_acc: 0.7363\n",
      "step 36, train_acc: 0.7361\n",
      "step 37, train_acc: 0.7380\n",
      "step 38, train_acc: 0.7374\n",
      "step 39, train_acc: 0.7372\n",
      "step 40, train_acc: 0.7372\n",
      "step 41, train_acc: 0.7362\n",
      "step 42, train_acc: 0.7361\n",
      "step 43, train_acc: 0.7362\n",
      "step 44, train_acc: 0.7358\n",
      "step 45, train_acc: 0.7360\n",
      "step 46, train_acc: 0.7357\n",
      "step 47, train_acc: 0.7368\n",
      "step 48, train_acc: 0.7359\n",
      "step 49, train_acc: 0.7365\n",
      "step 50, train_acc: 0.7362\n",
      "step 51, train_acc: 0.7361\n",
      "step 52, train_acc: 0.7367\n",
      "step 53, train_acc: 0.7362\n",
      "step 54, train_acc: 0.7360\n",
      "step 55, train_acc: 0.7365\n",
      "step 56, train_acc: 0.7357\n",
      "step 57, train_acc: 0.7360\n",
      "step 58, train_acc: 0.7353\n",
      "step 59, train_acc: 0.7353\n",
      "step 60, train_acc: 0.7355\n",
      "step 61, train_acc: 0.7358\n",
      "step 62, train_acc: 0.7361\n",
      "step 63, train_acc: 0.7361\n",
      "step 64, train_acc: 0.7362\n",
      "step 65, train_acc: 0.7356\n",
      "step 66, train_acc: 0.7352\n",
      "step 67, train_acc: 0.7355\n",
      "step 68, train_acc: 0.7359\n",
      "step 69, train_acc: 0.7364\n",
      "step 70, train_acc: 0.7361\n",
      "step 71, train_acc: 0.7366\n",
      "step 72, train_acc: 0.7373\n",
      "step 73, train_acc: 0.7370\n",
      "step 74, train_acc: 0.7370\n",
      "step 75, train_acc: 0.7373\n",
      "step 76, train_acc: 0.7369\n",
      "step 77, train_acc: 0.7369\n",
      "step 78, train_acc: 0.7364\n",
      "step 79, train_acc: 0.7366\n",
      "step 80, train_acc: 0.7371\n",
      "step 81, train_acc: 0.7369\n",
      "step 82, train_acc: 0.7368\n",
      "step 83, train_acc: 0.7367\n",
      "step 84, train_acc: 0.7370\n",
      "step 85, train_acc: 0.7370\n",
      "step 86, train_acc: 0.7374\n",
      "step 87, train_acc: 0.7378\n",
      "step 88, train_acc: 0.7378\n",
      "step 89, train_acc: 0.7376\n",
      "step 90, train_acc: 0.7375\n",
      "step 91, train_acc: 0.7379\n",
      "step 92, train_acc: 0.7382\n",
      "step 93, train_acc: 0.7387\n",
      "step 94, train_acc: 0.7389\n",
      "step 95, train_acc: 0.7387\n",
      "step 96, train_acc: 0.7388\n",
      "step 97, train_acc: 0.7390\n",
      "step 98, train_acc: 0.7386\n",
      "step 99, train_acc: 0.7384\n",
      "step 100, train_acc: 0.7384\n",
      "step 101, train_acc: 0.7386\n",
      "step 102, train_acc: 0.7389\n",
      "step 103, train_acc: 0.7388\n",
      "step 104, train_acc: 0.7387\n",
      "step 105, train_acc: 0.7382\n",
      "step 106, train_acc: 0.7383\n",
      "step 107, train_acc: 0.7384\n",
      "step 108, train_acc: 0.7380\n",
      "step 109, train_acc: 0.7380\n",
      "step 110, train_acc: 0.7377\n",
      "step 111, train_acc: 0.7379\n",
      "step 112, train_acc: 0.7379\n",
      "step 113, train_acc: 0.7380\n",
      "step 114, train_acc: 0.7380\n",
      "step 115, train_acc: 0.7377\n",
      "step 116, train_acc: 0.7377\n",
      "step 117, train_acc: 0.7375\n",
      "step 118, train_acc: 0.7379\n",
      "step 119, train_acc: 0.7379\n",
      "step 120, train_acc: 0.7379\n",
      "step 121, train_acc: 0.7376\n",
      "step 122, train_acc: 0.7379\n",
      "step 123, train_acc: 0.7382\n",
      "step 124, train_acc: 0.7381\n",
      "step 125, train_acc: 0.7386\n",
      "step 126, train_acc: 0.7388\n",
      "step 127, train_acc: 0.7383\n",
      "step 128, train_acc: 0.7383\n",
      "step 129, train_acc: 0.7386\n",
      "step 130, train_acc: 0.7388\n",
      "step 131, train_acc: 0.7385\n",
      "step 132, train_acc: 0.7383\n",
      "step 133, train_acc: 0.7383\n",
      "step 134, train_acc: 0.7385\n",
      "step 135, train_acc: 0.7384\n",
      "step 136, train_acc: 0.7380\n",
      "step 137, train_acc: 0.7383\n",
      "step 138, train_acc: 0.7384\n",
      "step 139, train_acc: 0.7386\n",
      "step 140, train_acc: 0.7381\n",
      "step 141, train_acc: 0.7381\n",
      "step 142, train_acc: 0.7381\n",
      "step 143, train_acc: 0.7385\n",
      "step 144, train_acc: 0.7384\n",
      "step 145, train_acc: 0.7384\n",
      "step 146, train_acc: 0.7385\n",
      "step 147, train_acc: 0.7386\n",
      "step 148, train_acc: 0.7385\n",
      "step 149, train_acc: 0.7386\n",
      "step 150, train_acc: 0.7388\n",
      "step 151, train_acc: 0.7391\n",
      "step 152, train_acc: 0.7392\n",
      "step 153, train_acc: 0.7392\n",
      "step 154, train_acc: 0.7392\n",
      "step 155, train_acc: 0.7391\n",
      "step 156, train_acc: 0.7390\n",
      "step 157, train_acc: 0.7393\n",
      "step 158, train_acc: 0.7395\n",
      "step 159, train_acc: 0.7395\n",
      "step 160, train_acc: 0.7396\n",
      "step 161, train_acc: 0.7393\n",
      "step 162, train_acc: 0.7394\n",
      "step 163, train_acc: 0.7395\n",
      "step 164, train_acc: 0.7395\n",
      "step 165, train_acc: 0.7393\n",
      "step 166, train_acc: 0.7392\n",
      "step 167, train_acc: 0.7392\n",
      "step 168, train_acc: 0.7394\n",
      "step 169, train_acc: 0.7394\n",
      "step 170, train_acc: 0.7393\n",
      "step 171, train_acc: 0.7394\n",
      "step 172, train_acc: 0.7395\n",
      "step 173, train_acc: 0.7396\n",
      "step 174, train_acc: 0.7395\n",
      "step 175, train_acc: 0.7396\n",
      "step 176, train_acc: 0.7396\n",
      "step 177, train_acc: 0.7396\n",
      "step 178, train_acc: 0.7396\n",
      "step 179, train_acc: 0.7397\n",
      "step 180, train_acc: 0.7397\n",
      "step 181, train_acc: 0.7397\n",
      "step 182, train_acc: 0.7395\n",
      "step 183, train_acc: 0.7397\n",
      "step 184, train_acc: 0.7396\n",
      "step 185, train_acc: 0.7395\n",
      "step 186, train_acc: 0.7395\n",
      "step 187, train_acc: 0.7395\n",
      "step 188, train_acc: 0.7395\n",
      "step 189, train_acc: 0.7396\n",
      "step 190, train_acc: 0.7394\n",
      "step 191, train_acc: 0.7392\n",
      "step 192, train_acc: 0.7390\n",
      "step 193, train_acc: 0.7389\n",
      "step 194, train_acc: 0.7390\n",
      "step 195, train_acc: 0.7391\n",
      "step 196, train_acc: 0.7391\n",
      "step 197, train_acc: 0.7392\n",
      "step 198, train_acc: 0.7390\n",
      "step 199, train_acc: 0.7392\n",
      "step 200, train_acc: 0.7395\n",
      "step 201, train_acc: 0.7394\n",
      "step 202, train_acc: 0.7395\n",
      "step 203, train_acc: 0.7394\n",
      "step 204, train_acc: 0.7396\n",
      "step 205, train_acc: 0.7397\n",
      "step 206, train_acc: 0.7396\n",
      "step 207, train_acc: 0.7396\n",
      "step 208, train_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 209, train_acc: 0.7395\n",
      "step 210, train_acc: 0.7393\n",
      "step 211, train_acc: 0.7394\n",
      "step 212, train_acc: 0.7393\n",
      "step 213, train_acc: 0.7391\n",
      "step 214, train_acc: 0.7392\n",
      "step 215, train_acc: 0.7393\n",
      "step 216, train_acc: 0.7395\n",
      "step 217, train_acc: 0.7395\n",
      "step 218, train_acc: 0.7396\n",
      "step 219, train_acc: 0.7399\n",
      "step 220, train_acc: 0.7400\n",
      "step 221, train_acc: 0.7400\n",
      "step 222, train_acc: 0.7399\n",
      "step 223, train_acc: 0.7397\n",
      "step 224, train_acc: 0.7398\n",
      "step 225, train_acc: 0.7398\n",
      "step 226, train_acc: 0.7400\n",
      "step 227, train_acc: 0.7400\n",
      "step 228, train_acc: 0.7400\n",
      "step 229, train_acc: 0.7402\n",
      "step 230, train_acc: 0.7401\n",
      "step 231, train_acc: 0.7402\n",
      "step 232, train_acc: 0.7400\n",
      "step 233, train_acc: 0.7398\n",
      "step 234, train_acc: 0.7399\n",
      "step 235, train_acc: 0.7399\n",
      "epoch 4, loss 0.6774, train acc 0.740, test acc 0.746, time 2.3 sec\n",
      "step 1, train_acc: 0.7148\n",
      "step 2, train_acc: 0.7441\n",
      "step 3, train_acc: 0.7526\n",
      "step 4, train_acc: 0.7451\n",
      "step 5, train_acc: 0.7523\n",
      "step 6, train_acc: 0.7598\n",
      "step 7, train_acc: 0.7584\n",
      "step 8, train_acc: 0.7583\n",
      "step 9, train_acc: 0.7617\n",
      "step 10, train_acc: 0.7645\n",
      "step 11, train_acc: 0.7607\n",
      "step 12, train_acc: 0.7604\n",
      "step 13, train_acc: 0.7608\n",
      "step 14, train_acc: 0.7581\n",
      "step 15, train_acc: 0.7560\n",
      "step 16, train_acc: 0.7532\n",
      "step 17, train_acc: 0.7532\n",
      "step 18, train_acc: 0.7526\n",
      "step 19, train_acc: 0.7514\n",
      "step 20, train_acc: 0.7537\n",
      "step 21, train_acc: 0.7493\n",
      "step 22, train_acc: 0.7484\n",
      "step 23, train_acc: 0.7478\n",
      "step 24, train_acc: 0.7474\n",
      "step 25, train_acc: 0.7459\n",
      "step 26, train_acc: 0.7464\n",
      "step 27, train_acc: 0.7459\n",
      "step 28, train_acc: 0.7457\n",
      "step 29, train_acc: 0.7469\n",
      "step 30, train_acc: 0.7474\n",
      "step 31, train_acc: 0.7485\n",
      "step 32, train_acc: 0.7474\n",
      "step 33, train_acc: 0.7480\n",
      "step 34, train_acc: 0.7471\n",
      "step 35, train_acc: 0.7461\n",
      "step 36, train_acc: 0.7464\n",
      "step 37, train_acc: 0.7462\n",
      "step 38, train_acc: 0.7463\n",
      "step 39, train_acc: 0.7459\n",
      "step 40, train_acc: 0.7454\n",
      "step 41, train_acc: 0.7453\n",
      "step 42, train_acc: 0.7458\n",
      "step 43, train_acc: 0.7445\n",
      "step 44, train_acc: 0.7448\n",
      "step 45, train_acc: 0.7456\n",
      "step 46, train_acc: 0.7471\n",
      "step 47, train_acc: 0.7471\n",
      "step 48, train_acc: 0.7470\n",
      "step 49, train_acc: 0.7465\n",
      "step 50, train_acc: 0.7470\n",
      "step 51, train_acc: 0.7465\n",
      "step 52, train_acc: 0.7468\n",
      "step 53, train_acc: 0.7473\n",
      "step 54, train_acc: 0.7473\n",
      "step 55, train_acc: 0.7479\n",
      "step 56, train_acc: 0.7488\n",
      "step 57, train_acc: 0.7487\n",
      "step 58, train_acc: 0.7481\n",
      "step 59, train_acc: 0.7479\n",
      "step 60, train_acc: 0.7483\n",
      "step 61, train_acc: 0.7477\n",
      "step 62, train_acc: 0.7469\n",
      "step 63, train_acc: 0.7471\n",
      "step 64, train_acc: 0.7477\n",
      "step 65, train_acc: 0.7481\n",
      "step 66, train_acc: 0.7485\n",
      "step 67, train_acc: 0.7489\n",
      "step 68, train_acc: 0.7500\n",
      "step 69, train_acc: 0.7502\n",
      "step 70, train_acc: 0.7499\n",
      "step 71, train_acc: 0.7508\n",
      "step 72, train_acc: 0.7506\n",
      "step 73, train_acc: 0.7506\n",
      "step 74, train_acc: 0.7505\n",
      "step 75, train_acc: 0.7507\n",
      "step 76, train_acc: 0.7506\n",
      "step 77, train_acc: 0.7507\n",
      "step 78, train_acc: 0.7513\n",
      "step 79, train_acc: 0.7512\n",
      "step 80, train_acc: 0.7511\n",
      "step 81, train_acc: 0.7515\n",
      "step 82, train_acc: 0.7519\n",
      "step 83, train_acc: 0.7524\n",
      "step 84, train_acc: 0.7521\n",
      "step 85, train_acc: 0.7521\n",
      "step 86, train_acc: 0.7517\n",
      "step 87, train_acc: 0.7514\n",
      "step 88, train_acc: 0.7518\n",
      "step 89, train_acc: 0.7519\n",
      "step 90, train_acc: 0.7523\n",
      "step 91, train_acc: 0.7521\n",
      "step 92, train_acc: 0.7525\n",
      "step 93, train_acc: 0.7526\n",
      "step 94, train_acc: 0.7528\n",
      "step 95, train_acc: 0.7532\n",
      "step 96, train_acc: 0.7534\n",
      "step 97, train_acc: 0.7532\n",
      "step 98, train_acc: 0.7536\n",
      "step 99, train_acc: 0.7538\n",
      "step 100, train_acc: 0.7538\n",
      "step 101, train_acc: 0.7541\n",
      "step 102, train_acc: 0.7544\n",
      "step 103, train_acc: 0.7548\n",
      "step 104, train_acc: 0.7547\n",
      "step 105, train_acc: 0.7548\n",
      "step 106, train_acc: 0.7544\n",
      "step 107, train_acc: 0.7547\n",
      "step 108, train_acc: 0.7547\n",
      "step 109, train_acc: 0.7547\n",
      "step 110, train_acc: 0.7544\n",
      "step 111, train_acc: 0.7544\n",
      "step 112, train_acc: 0.7546\n",
      "step 113, train_acc: 0.7544\n",
      "step 114, train_acc: 0.7544\n",
      "step 115, train_acc: 0.7548\n",
      "step 116, train_acc: 0.7550\n",
      "step 117, train_acc: 0.7556\n",
      "step 118, train_acc: 0.7559\n",
      "step 119, train_acc: 0.7561\n",
      "step 120, train_acc: 0.7565\n",
      "step 121, train_acc: 0.7565\n",
      "step 122, train_acc: 0.7567\n",
      "step 123, train_acc: 0.7565\n",
      "step 124, train_acc: 0.7564\n",
      "step 125, train_acc: 0.7566\n",
      "step 126, train_acc: 0.7567\n",
      "step 127, train_acc: 0.7569\n",
      "step 128, train_acc: 0.7569\n",
      "step 129, train_acc: 0.7570\n",
      "step 130, train_acc: 0.7566\n",
      "step 131, train_acc: 0.7567\n",
      "step 132, train_acc: 0.7567\n",
      "step 133, train_acc: 0.7567\n",
      "step 134, train_acc: 0.7565\n",
      "step 135, train_acc: 0.7567\n",
      "step 136, train_acc: 0.7566\n",
      "step 137, train_acc: 0.7566\n",
      "step 138, train_acc: 0.7567\n",
      "step 139, train_acc: 0.7567\n",
      "step 140, train_acc: 0.7569\n",
      "step 141, train_acc: 0.7570\n",
      "step 142, train_acc: 0.7569\n",
      "step 143, train_acc: 0.7569\n",
      "step 144, train_acc: 0.7568\n",
      "step 145, train_acc: 0.7566\n",
      "step 146, train_acc: 0.7566\n",
      "step 147, train_acc: 0.7563\n",
      "step 148, train_acc: 0.7562\n",
      "step 149, train_acc: 0.7561\n",
      "step 150, train_acc: 0.7561\n",
      "step 151, train_acc: 0.7561\n",
      "step 152, train_acc: 0.7560\n",
      "step 153, train_acc: 0.7560\n",
      "step 154, train_acc: 0.7564\n",
      "step 155, train_acc: 0.7565\n",
      "step 156, train_acc: 0.7563\n",
      "step 157, train_acc: 0.7562\n",
      "step 158, train_acc: 0.7563\n",
      "step 159, train_acc: 0.7565\n",
      "step 160, train_acc: 0.7564\n",
      "step 161, train_acc: 0.7563\n",
      "step 162, train_acc: 0.7562\n",
      "step 163, train_acc: 0.7560\n",
      "step 164, train_acc: 0.7562\n",
      "step 165, train_acc: 0.7562\n",
      "step 166, train_acc: 0.7559\n",
      "step 167, train_acc: 0.7562\n",
      "step 168, train_acc: 0.7563\n",
      "step 169, train_acc: 0.7563\n",
      "step 170, train_acc: 0.7559\n",
      "step 171, train_acc: 0.7560\n",
      "step 172, train_acc: 0.7557\n",
      "step 173, train_acc: 0.7559\n",
      "step 174, train_acc: 0.7558\n",
      "step 175, train_acc: 0.7560\n",
      "step 176, train_acc: 0.7560\n",
      "step 177, train_acc: 0.7558\n",
      "step 178, train_acc: 0.7560\n",
      "step 179, train_acc: 0.7558\n",
      "step 180, train_acc: 0.7558\n",
      "step 181, train_acc: 0.7559\n",
      "step 182, train_acc: 0.7559\n",
      "step 183, train_acc: 0.7561\n",
      "step 184, train_acc: 0.7561\n",
      "step 185, train_acc: 0.7561\n",
      "step 186, train_acc: 0.7563\n",
      "step 187, train_acc: 0.7563\n",
      "step 188, train_acc: 0.7563\n",
      "step 189, train_acc: 0.7563\n",
      "step 190, train_acc: 0.7560\n",
      "step 191, train_acc: 0.7559\n",
      "step 192, train_acc: 0.7561\n",
      "step 193, train_acc: 0.7562\n",
      "step 194, train_acc: 0.7562\n",
      "step 195, train_acc: 0.7565\n",
      "step 196, train_acc: 0.7565\n",
      "step 197, train_acc: 0.7563\n",
      "step 198, train_acc: 0.7563\n",
      "step 199, train_acc: 0.7563\n",
      "step 200, train_acc: 0.7564\n",
      "step 201, train_acc: 0.7561\n",
      "step 202, train_acc: 0.7560\n",
      "step 203, train_acc: 0.7558\n",
      "step 204, train_acc: 0.7558\n",
      "step 205, train_acc: 0.7559\n",
      "step 206, train_acc: 0.7560\n",
      "step 207, train_acc: 0.7561\n",
      "step 208, train_acc: 0.7563\n",
      "step 209, train_acc: 0.7564\n",
      "step 210, train_acc: 0.7566\n",
      "step 211, train_acc: 0.7566\n",
      "step 212, train_acc: 0.7565\n",
      "step 213, train_acc: 0.7565\n",
      "step 214, train_acc: 0.7564\n",
      "step 215, train_acc: 0.7565\n",
      "step 216, train_acc: 0.7566\n",
      "step 217, train_acc: 0.7567\n",
      "step 218, train_acc: 0.7565\n",
      "step 219, train_acc: 0.7566\n",
      "step 220, train_acc: 0.7566\n",
      "step 221, train_acc: 0.7566\n",
      "step 222, train_acc: 0.7567\n",
      "step 223, train_acc: 0.7568\n",
      "step 224, train_acc: 0.7567\n",
      "step 225, train_acc: 0.7567\n",
      "step 226, train_acc: 0.7566\n",
      "step 227, train_acc: 0.7566\n",
      "step 228, train_acc: 0.7566\n",
      "step 229, train_acc: 0.7567\n",
      "step 230, train_acc: 0.7567\n",
      "step 231, train_acc: 0.7566\n",
      "step 232, train_acc: 0.7565\n",
      "step 233, train_acc: 0.7565\n",
      "step 234, train_acc: 0.7563\n",
      "step 235, train_acc: 0.7563\n",
      "epoch 5, loss 0.6222, train acc 0.756, test acc 0.761, time 2.3 sec\n"
     ]
    }
   ],
   "source": [
    "lr, epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 卷积神经网络就是含卷积层的网络。\n",
    "+ LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyc",
   "language": "python",
   "name": "fyc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
