{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归的简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.4655,  2.4932, 10.4394, 10.4440, 10.9183,  3.1116,  2.8337,  4.9631,\n",
       "         4.2497,  5.2911,  1.9516,  8.9086,  4.6084,  3.8854, -0.2705,  4.6349,\n",
       "         7.8503,  8.7553,  7.6756,  3.6597,  3.6466,  5.4732,  0.3920,  5.1678,\n",
       "        -1.1402,  4.6748, 10.4345,  6.4641,  8.8305,  6.8826,  8.2196,  4.9940,\n",
       "         5.9900,  5.7975,  4.2658,  3.8463,  5.9819,  7.1331,  8.3011,  3.2582,\n",
       "         7.5125,  9.0564,  9.3552,  3.6004,  5.1539, 10.6855,  3.3712,  6.3470,\n",
       "         8.9445,  3.7684,  5.7342,  3.1631,  8.6203,  7.5955,  1.2284,  5.4802,\n",
       "         6.0713,  3.7136,  9.9302,  6.6225,  4.0045,  4.7726,  4.0944,  6.6271,\n",
       "         2.1045,  4.0181,  3.0088,  8.6568,  3.8279,  8.7602,  4.8629,  5.0880,\n",
       "         6.9240,  6.9412,  2.0965,  6.4297,  6.0086,  9.4800,  1.4377,  8.2213,\n",
       "         5.9989,  3.6668,  5.7243,  7.3405,  6.3130,  4.9544,  6.5486,  1.1333,\n",
       "         4.8474,  5.5174,  5.7575,  6.5295,  7.9151,  3.4282,  2.2480,  5.4171,\n",
       "         9.5149,  8.1106,  5.9820,  2.9107,  5.0573,  5.0612,  4.8128, 12.6473,\n",
       "         3.8097,  5.8425, 12.6623,  7.7121,  3.5801,  7.1839,  9.0973,  5.4573,\n",
       "         6.1714,  4.3798,  4.2071,  7.2263,  5.4935,  1.8167,  7.8902,  2.0232,\n",
       "         1.3743, 11.5108,  4.5388,  6.7137,  8.8420,  7.7513,  8.0513,  7.3855,\n",
       "         5.1705,  1.3452,  5.6926,  6.0019,  9.5070,  0.4365,  2.7120, -2.4178,\n",
       "        11.6556,  6.8312,  6.7296,  8.4278,  5.9958,  4.1243,  5.5154,  6.9061,\n",
       "         4.5643,  5.6755,  6.4282,  6.5694, 14.0858,  5.0137,  2.4242,  8.7860,\n",
       "         4.1382,  5.3872,  8.9465,  8.3037,  8.9970,  1.7543,  7.5852,  5.5318,\n",
       "         1.8485,  2.6486,  2.1410,  7.2311, 10.5730,  6.7313,  7.5456,  1.7832,\n",
       "         1.8347,  6.6924,  7.2235,  5.5633,  0.5484,  8.2393,  6.6907,  5.4189,\n",
       "         2.4940,  6.0047,  3.4050,  5.2365,  2.6096,  2.3498,  4.1754,  1.9720,\n",
       "        10.4852,  2.2757,  3.7630,  4.1615,  4.2557,  4.7127,  7.0075,  9.5466,\n",
       "         8.2874, -1.9463,  4.6759,  7.1602,  8.6861,  4.8609, -0.5899,  7.1258,\n",
       "         2.1526,  2.3680,  5.5808,  6.1408,  6.1281,  6.2890,  1.3233,  0.7727,\n",
       "         7.9202,  9.8316,  9.5883,  6.6767, 12.0348,  4.5777,  7.9426,  3.0126,\n",
       "         4.5295,  3.2782,  6.0638,  7.8699,  3.7795,  3.0164,  5.7630, 10.0392,\n",
       "         7.9963,  3.1144,  6.6126,  6.1913,  8.3519,  9.5564,  2.3134,  6.7177,\n",
       "        10.3591,  8.2512,  9.4313,  4.8806,  4.1130,  3.1071,  8.4251, -1.4109,\n",
       "         9.6811,  1.2597,  3.5058,  5.6774,  5.6611,  5.0061,  2.4571,  4.5491,\n",
       "         9.6168,  7.1394,  6.7715, 10.9376,  4.6559,  7.4406,  6.5748,  6.0998,\n",
       "         4.1403,  4.1725,  4.5051,  5.5748, 12.0053,  6.2688, 11.7084,  7.2877,\n",
       "         7.0217,  3.1644,  8.6625,  6.0917, 10.5228,  4.3287,  4.2031,  2.8334,\n",
       "         8.2984,  5.6208,  5.8156,  3.9156,  8.1138,  2.9741,  6.2412,  8.0418,\n",
       "         3.7776,  4.7184, -1.7079,  5.5029, -0.5146,  3.7393,  4.8940,  8.5943,\n",
       "         6.1017,  7.3227,  3.7769,  0.8734,  6.1156,  5.5376,  3.5863, 10.4367,\n",
       "         6.2039,  3.6566,  0.0384,  1.0011,  7.7176,  2.9401, 11.1346,  7.3723,\n",
       "         8.8642,  2.4274,  5.8599,  6.6234,  9.7048,  5.1914,  9.4327,  4.8195,\n",
       "         4.3508,  4.9426,  4.5944,  4.3270,  7.1691,  4.5583,  6.0462,  4.7168,\n",
       "         4.2429,  4.2284,  6.6587,  9.0503,  7.6103,  7.6981,  7.4269,  3.6697,\n",
       "        -2.4063,  4.8199,  1.9424,  9.6970,  4.3214, -2.1626,  5.0217,  5.9161,\n",
       "         3.1043,  8.8390,  4.6027,  7.1014,  7.4446,  7.3421,  2.9048,  5.1754,\n",
       "         7.5268,  3.7706,  1.8779,  8.1457,  3.4133,  5.3250,  5.5069,  6.9616,\n",
       "         7.0553,  6.3431,  4.9130,  5.7575,  1.5111,  1.0095,  7.3399,  4.2108,\n",
       "         4.0886,  8.3185,  3.5798,  3.9603,  6.8251,  1.9079,  7.8463,  7.6234,\n",
       "         3.9228,  3.0689,  7.2051,  4.5087,  5.3520,  5.0054,  9.2597,  7.5591,\n",
       "         7.6363,  9.5966,  3.0626,  2.3082,  5.3190,  6.9931,  8.1647,  3.3767,\n",
       "         5.0634,  8.6916,  7.1804,  6.3180,  6.5265, 12.2964,  0.8718,  0.3046,\n",
       "         4.8711,  9.8080,  2.4510,  2.5592,  6.5544,  5.6014,  9.2623,  4.2313,\n",
       "         7.5922,  5.1666,  7.4650,  8.9118,  6.2789,  0.4028,  1.9808,  1.3130,\n",
       "         0.7020,  2.2579,  2.4708,  7.6119,  6.0918,  6.9910,  5.5033,  7.3271,\n",
       "         5.9212,  7.5433,  8.1133,  4.8999,  4.9307,  2.7700, -2.0460,  5.7445,\n",
       "        13.9901,  8.3302,  3.9052,  6.6331,  5.8383,  2.1536,  4.3319,  5.0440,\n",
       "         8.3645,  2.4736,  9.1902,  4.7358,  7.4095,  8.5787,  5.0872,  8.1143,\n",
       "         6.5418,  3.0220, 10.3723,  2.6620,  3.5956,  2.4748,  5.9391,  7.1806,\n",
       "         7.3922,  8.6439,  3.8274, 10.7468,  5.1258,  4.8003,  9.9322,  7.2166,\n",
       "        11.2159,  5.7981,  5.3363,  5.0777,  6.2238,  6.8794,  6.8597,  4.5880,\n",
       "         6.4338,  3.3576,  5.7252,  2.7304,  8.8972,  5.5177,  4.1140, -1.2647,\n",
       "        14.6754,  4.9931,  7.4406,  7.0760,  3.4588,  3.9041,  8.4669,  4.0221,\n",
       "         6.3992,  7.7772,  6.2628,  3.3860,  6.3274,  3.3400,  7.9451,  5.7793,\n",
       "         5.3644,  8.8136,  4.5984,  5.2335,  8.0065,  4.1015,  1.8039,  9.0360,\n",
       "         5.1008, 10.6065,  5.4653,  5.9383,  5.5266,  6.2341,  7.5971,  6.7980,\n",
       "         1.6744,  5.7999,  7.2408,  4.6487, 10.7520,  6.0661, 11.1211,  5.3669,\n",
       "        10.7616,  5.8104,  5.8133,  2.5213,  0.5984,  1.1212,  8.5916,  5.1696,\n",
       "         0.0302, -0.3139,  4.2834,  3.0879,  8.2101, 11.5649, 11.2672,  3.1263,\n",
       "         2.7075, 10.1146,  6.7818,  3.6858, -0.6249,  5.1708,  2.1965,  6.3072,\n",
       "         6.7711,  2.9638,  5.4424,  6.2798, 10.7532,  8.7417,  9.4618,  3.9850,\n",
       "         6.0450,  1.6128,  9.2212,  4.6647,  3.0452,  2.1021,  3.2539, 10.7161,\n",
       "         2.1352,  3.8736,  8.1834,  3.5034,  7.3949, 10.4859,  2.5337,  6.0521,\n",
       "         2.3450,  6.9336,  4.7615,  5.8361,  5.8608,  4.4024,  9.0261,  5.2855,\n",
       "         6.3585,  3.3907,  0.9175,  4.9044,  4.0037,  5.0987, -0.2390, 12.2077,\n",
       "         6.7139, 10.0864,  5.6274,  3.1892,  3.4260,  4.6855,  3.4557, 11.2470,\n",
       "         2.4994,  8.7357,  5.3271,  5.7689,  5.3894,  5.0828,  4.1896,  6.7181,\n",
       "         0.1229,  4.3639,  5.4912, 10.2463,  7.6569,  9.5644,  4.0600,  4.7325,\n",
       "         6.2895,  1.5156,  3.1656,  4.4259,  6.8341,  4.6689, 10.4187,  5.6783,\n",
       "         9.4931,  2.8928,  6.0898,  8.9451,  6.7657, 12.1912,  0.9340,  2.3422,\n",
       "        10.8915,  6.7160,  4.9511,  6.3582,  6.9330,  4.1682,  5.7098,  3.5249,\n",
       "         7.6057,  3.0939,  2.9710,  3.3718,  3.9707, -1.0082,  2.9755, -0.0484,\n",
       "         3.2784,  6.1179,  3.0468,  6.4164,  8.4709,  5.1843,  4.8903,  8.3855,\n",
       "         4.2460,  4.6851,  7.4270,  6.2985,  5.7649,  7.7714,  7.3287,  5.5564,\n",
       "         4.1730,  7.9920,  6.9545,  5.9551, -1.9928,  5.5364,  8.3629,  6.5737,\n",
       "         5.1959,  7.7779,  4.4856,  4.5434,  3.2216,  7.5999,  9.8941,  9.1784,\n",
       "         5.5966,  1.8341,  1.6641,  8.1384,  5.6083,  8.8192,  7.3774,  8.0702,\n",
       "         7.1037,  4.9348,  2.6978, -0.1474,  7.7948,  4.8078,  1.5674,  7.0560,\n",
       "         5.3239,  6.3911,  3.8351,  4.4064, 10.5625,  3.4819,  4.1465,  3.8537,\n",
       "         6.8412, -0.6576,  7.5609,  6.2224,  8.2965,  1.9218,  7.6782,  3.3932,\n",
       "         5.7464,  8.8655, 10.5017,  6.4116,  1.8849,  7.0141,  7.2710,  5.2251,\n",
       "        11.5287,  6.7435,  5.5347,  8.4206,  8.6462,  5.8949,  3.0137,  4.0967,\n",
       "         5.1036,  8.6275,  7.0986,  6.6612,  2.7508,  4.1649,  8.1231,  0.0394,\n",
       "         3.5508,  3.6601,  6.6399,  6.0337,  8.0410,  3.2708,  4.6866,  7.2134,\n",
       "         6.5789,  7.9023,  4.3512,  7.4501,  2.5494,  5.1356,  4.0817,  6.5994,\n",
       "         0.7803,  8.1241,  5.1671,  8.4247,  8.3341, 13.5144,  9.5889,  4.8755,\n",
       "         2.2108,  5.4881,  7.5320, 10.0935,  7.6096,  3.7811,  6.7635,  7.9644,\n",
       "         7.2446,  1.3810,  7.3220,  1.8219,  6.6672,  0.8470,  3.9675,  2.7741,\n",
       "         7.0175,  7.2953,  5.2837,  1.6699,  5.4249,  8.7610,  8.6143,  1.7053,\n",
       "         1.8050,  2.9787,  8.8741,  6.2134,  5.1703,  4.5422,  6.3550,  4.2974,\n",
       "         6.5133, 10.1916,  1.9134,  4.7513,  8.0736,  8.0316,  5.4603,  2.1715,\n",
       "         2.7600,  8.4165,  9.8006,  8.8952,  6.0034,  5.1270,  5.5503,  1.6767,\n",
       "         2.3579,  5.4944,  7.3131,  8.0366,  1.8499,  8.4024,  7.9793,  5.7178,\n",
       "         5.6360,  6.6995,  5.6394,  2.1065,  7.7596,  0.1455,  6.8466,  5.3911,\n",
       "        11.2638,  1.7146,  7.1561,  3.0638,  5.9675,  5.3909,  4.2354,  7.5414,\n",
       "         3.8640,  6.9382,  7.6346,  7.4028,  8.4426,  5.7251,  4.5434,  5.9853,\n",
       "         0.1231,  7.2465,  6.0780,  8.8536,  2.5085,  6.6710,  8.3165,  2.1296,\n",
       "         6.3572,  7.8165,  4.5614,  0.7509,  7.1507,  1.9710,  7.3873, 10.7827,\n",
       "         1.9235,  3.8809,  6.7665,  7.4898,  6.3018,  9.6651,  4.0467,  0.8651,\n",
       "         9.6510,  8.5225,  5.2819,  7.5276,  3.1028,  3.1353,  2.4898,  8.3361,\n",
       "         5.7548,  3.1703,  4.5027, 11.0337,  6.8924,  7.0418,  4.8204,  4.2178,\n",
       "         0.1581,  8.6500,  3.4872,  4.2488,  9.5138, 13.4848,  3.1606,  1.5461,\n",
       "         5.8582,  5.0126,  2.1022,  6.4749,  6.0546,  3.1695,  8.5258,  3.3559,\n",
       "         1.9390,  5.7547,  1.0626,  7.2889,  9.7561,  6.7764,  2.5656,  4.7455,\n",
       "        -0.3187,  5.7415,  5.1657,  7.5759,  3.6875,  2.7725,  9.8912,  6.1990,\n",
       "         3.1078,  6.0647,  9.2761,  5.7862,  5.3342,  6.6669,  3.4013,  7.4227,\n",
       "         5.1573,  3.2527,  5.3623, 11.2059,  2.3990, 11.5684,  1.1185,  3.3920,\n",
       "         9.7990,  1.5625,  6.7492,  6.9180,  3.7934, -1.2032,  6.9050,  3.7702,\n",
       "         6.0892,  2.1069,  7.9339, -0.9395,  6.5113,  6.2305,  3.1423,  0.6501,\n",
       "         9.1389,  6.3706,  5.8631,  2.1358, 12.7471,  6.7722,  3.7843, 10.4525,\n",
       "         4.3090, 12.6054, 10.1169,  3.8721,  5.2720,  0.5921,  6.7820,  6.0315,\n",
       "         7.1737,  6.5427,  5.7538, 10.4623,  0.8805,  8.3372,  9.2784,  1.0821,\n",
       "         6.8464,  4.6370,  1.1228,  0.3957, 10.3090,  2.8247,  7.3185,  4.8823,\n",
       "         4.3104,  2.9386,  7.2344,  3.4858,  2.5408,  7.8917,  3.5863,  6.1775,\n",
       "         6.3985,  8.6692,  3.0030,  1.7758,  6.7920,  7.9567, -0.1849,  3.8650,\n",
       "         5.0927,  5.0327,  4.6077,  6.5532,  3.6828,  7.1126, -0.0769,  2.7136,\n",
       "         1.9007,  3.2047,  8.6053,  7.2331,  5.0409,  7.5340,  4.7994,  8.1220,\n",
       "         4.5086,  6.4491,  8.8543,  5.2973,  5.6228,  3.0422,  6.1945,  1.4078])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features=2\n",
    "num_examples=1000\n",
    "true_w=[2,-2]\n",
    "true_b=5.5\n",
    "examples = torch.randn(num_examples,num_features,dtype=torch.float32)\n",
    "labels = true_w[0]*examples[:,0]+true_w[1]*examples[:,1]+true_b\n",
    "labels+=torch.tensor(np.random.normal(0,0.01,size=labels.size())\n",
    "                    ,dtype=torch.float32)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "batch_size = 10\n",
    "# 将特征与标签合并\n",
    "dataset = Data.TensorDataset(examples,labels)\n",
    "# 随机读取小批量数据\n",
    "data_iter = Data.DataLoader(dataset,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用Sequential搭建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "net = nn.Sequential()\n",
    "net.add_module('linear',nn.Linear(num_features,1))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化模型参数\n",
    "\n",
    "$w$采样于均值为$0$，标准差为$0.01$的正态分布，$b$为$0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.normal_(net[0].weight, mean=0, std=0.01)\n",
    "nn.init.constant_(net[0].bias,val=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用nn自带的MSE损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用torch.optim中带的SGD优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.01)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 , loss 0.573764\n",
      "epoch 2 , loss 0.011898\n",
      "epoch 3 , loss 0.000359\n",
      "epoch 4 , loss 0.000099\n",
      "epoch 5 , loss 0.000050\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "for epoch in range(1,epochs+1):\n",
    "    for X,y in data_iter:\n",
    "        sum_loss = loss(net(X),y.view(-1,1)) #求样本损失和\n",
    "        optimizer.zero_grad()\n",
    "        sum_loss.backward() #求梯度\n",
    "        optimizer.step() #使用SGD优化参数\n",
    "    print('epoch %d , loss %f' % (epoch,sum_loss.item()))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 2.0004, -2.0002]], requires_grad=True) \n",
      " [2, -2]\n",
      "Parameter containing:\n",
      "tensor([5.4991], requires_grad=True) \n",
      " 5.5\n"
     ]
    }
   ],
   "source": [
    "print(net[0].weight,'\\n',true_w)\n",
    "print(net[0].bias,'\\n',true_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$torch.utils.data$模块提供了有关数据处理的工具\n",
    "\n",
    "$torch.nn$模块定义了大量神经网络的层\n",
    "\n",
    "$torch.nn.init$模块定义了各种初始化方法\n",
    "\n",
    "$torch.optim$模块提供了模型参数初始化的各种方法。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
